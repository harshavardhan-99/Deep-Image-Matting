{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from DataLoader.ipynb\n",
      "Importing Jupyter notebook from ConvNet.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import nbimporter\n",
    "from DataLoader import load_dataset\n",
    "from ConvNet import get_model\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_stage1(alpha, trimap, pred_alpha, fg, bg, img, cuda):\n",
    "    wi = torch.zeros(trimap.shape)\n",
    "    wi[trimap == 128] = 1.\n",
    "    t_wi = wi\n",
    "    t3_wi = torch.cat((wi, wi, wi), 1)\n",
    "    if cuda:\n",
    "        t3_wi = t3_wi.cuda()\n",
    "        t_wi = wi.cuda()\n",
    "\n",
    "    unknown_region_size = t_wi.sum()\n",
    "\n",
    "    # alpha loss\n",
    "    alpha = alpha / 255.\n",
    "    alpha_loss = torch.sqrt((pred_alpha - alpha)**2 + 1e-12)\n",
    "    alpha_loss = (alpha_loss * t_wi).sum() / (unknown_region_size + 1.)\n",
    "\n",
    "    # composite rgb loss\n",
    "    pred_alpha_3 = torch.cat((pred_alpha, pred_alpha, pred_alpha), 1)\n",
    "#     print(fg.shape, bg.shape, pred_alpha_3.shape)\n",
    "    comp = pred_alpha_3 * fg + (1. - pred_alpha_3) * bg\n",
    "    comp_loss = torch.sqrt((comp - img) ** 2 + 1e-12) / 255.\n",
    "    comp_loss = (comp_loss * t3_wi).sum() / (unknown_region_size + 1.) / 3.\n",
    "    return alpha_loss, comp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep checking learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lr(optimizer, epoch):\n",
    "    if epoch >= 10:\n",
    "        for param_group in opt.param_groups:\n",
    "            param_group['lr'] *= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_pretrain_vals(model, vgg_dict):\n",
    "    model.load_state_dict(vgg_dict,strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a file list array for data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_list(fg_file, bg_file):\n",
    "    fg_list = []\n",
    "    bg_list = []\n",
    "    with open(fg_file, 'r') as f:\n",
    "        fg_list = f.readlines()\n",
    "    with open(bg_file, 'r') as f:\n",
    "        bg_list = f.readlines()\n",
    "    for i in range(len(fg_list)):\n",
    "        fg_list[i] = fg_list[i].strip('\\n').strip('\\r')\n",
    "    for i in range(len(bg_list)):\n",
    "        bg_list[i] = bg_list[i].strip('\\n').strip('\\r')\n",
    "    arr = []\n",
    "    cnt = 0\n",
    "    for i in range(len(fg_list)):\n",
    "        for j in range(100):\n",
    "            arr.append((fg_list[i], bg_list[cnt], fg_list[i]))\n",
    "            cnt += 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, dataset, epoch, cuda=False):\n",
    "    model.train()\n",
    "#     for iteration, batch in enumerate(dataset, 1):\n",
    "#         print(iteration)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(iteration, epoch)\n",
    "#         print(batch[0].shape, batch[1].shape, batch[2].shape, batch[3].shape, batch[4].shape)\n",
    "#         img = Variable(batch[0])\n",
    "#         alpha = Variable(batch[1])\n",
    "#         fg = Variable(batch[2])\n",
    "#         bg = Variable(batch[3])\n",
    "#         trimap = Variable(batch[4])\n",
    "\n",
    "#         if cuda:\n",
    "#             img = img.cuda()\n",
    "#             alpha = alpha.cuda()\n",
    "#             fg = fg.cuda()\n",
    "#             bg = bg.cuda()\n",
    "#             trimap = trimap.cuda()\n",
    "\n",
    "#         check_lr(optimizer, epoch)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         pred_alpha = model(torch.cat((img, trimap), 1))\n",
    "\n",
    "#         alpha_loss, comp_loss = loss_stage1(alpha, trimap, pred_alpha, fg, bg, img, cuda)\n",
    "#         loss = alpha_loss*0.5 + comp_loss*0.5\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    for iteration in range(dataset.__len__()):\n",
    "#         print(iteration)\n",
    "        torch.cuda.empty_cache()\n",
    "        batch = dataset.__getitem__(iteration)\n",
    "        if batch == None:\n",
    "            continue\n",
    "#         print(batch[0].shape)\n",
    "#         print(batch[0])\n",
    "        batch0 = batch[0].reshape(1, batch[0].shape[0], batch[0].shape[1], batch[0].shape[2])\n",
    "        batch1 = batch[1].reshape(1, batch[1].shape[0], batch[1].shape[1], batch[1].shape[2])\n",
    "        batch2 = batch[2].reshape(1, batch[2].shape[0], batch[2].shape[1], batch[2].shape[2])\n",
    "        batch3 = batch[3].reshape(1, batch[3].shape[0], batch[3].shape[1], batch[3].shape[2])\n",
    "        batch4 = batch[4].reshape(1, batch[4].shape[0], batch[4].shape[1], batch[4].shape[2])\n",
    "        img = Variable(batch0)\n",
    "        alpha = Variable(batch1)\n",
    "        fg = Variable(batch2)\n",
    "        bg = Variable(batch3)\n",
    "        trimap = Variable(batch4)\n",
    "#         print(batch[0].shape, batch[1].shape, batch[2].shape, batch[3].shape, batch[4].shape)\n",
    "#         print(img.shape, alpha.shape, bg.shape, fg.shape, trimap.shape)\n",
    "\n",
    "        if cuda:\n",
    "            img = img.cuda()\n",
    "            alpha = alpha.cuda()\n",
    "            fg = fg.cuda()\n",
    "            bg = bg.cuda()\n",
    "            trimap = trimap.cuda()\n",
    "\n",
    "        check_lr(optimizer, epoch)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_alpha = model(torch.cat((img, trimap), 1))\n",
    "\n",
    "        alpha_loss, comp_loss = loss_stage1(alpha, trimap, pred_alpha, fg, bg, img, cuda)\n",
    "        loss = alpha_loss*0.5 + comp_loss*0.5\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % 1 == 0:\n",
    "            print(iteration, epoch, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(path, model):\n",
    "    torch.save(model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(1, 0, tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(2, 0, tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(3, 0, tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(4, 0, tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(5, 0, tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(6, 0, tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(7, 0, tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(8, 0, tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(9, 0, tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(10, 0, tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(11, 0, tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(12, 0, tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(13, 0, tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(14, 0, tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(15, 0, tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(16, 0, tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(17, 0, tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(18, 0, tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(19, 0, tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(20, 0, tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(21, 0, tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(22, 0, tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(23, 0, tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(24, 0, tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(25, 0, tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(26, 0, tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(27, 0, tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(28, 0, tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(29, 0, tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(30, 0, tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(31, 0, tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(32, 0, tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(33, 0, tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(34, 0, tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(35, 0, tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(36, 0, tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(37, 0, tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(38, 0, tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(39, 0, tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(40, 0, tensor(0.1488, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(41, 0, tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(42, 0, tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(43, 0, tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(44, 0, tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(45, 0, tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(46, 0, tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(47, 0, tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(48, 0, tensor(0.1281, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(49, 0, tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(50, 0, tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(51, 0, tensor(0.1538, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(52, 0, tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(53, 0, tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(54, 0, tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(55, 0, tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(56, 0, tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(57, 0, tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(58, 0, tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(59, 0, tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(60, 0, tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(61, 0, tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(62, 0, tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(63, 0, tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(64, 0, tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(65, 0, tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(66, 0, tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(67, 0, tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(68, 0, tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(69, 0, tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(70, 0, tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(71, 0, tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(72, 0, tensor(0.1354, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(73, 0, tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(74, 0, tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(75, 0, tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(76, 0, tensor(0.1674, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(77, 0, tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(78, 0, tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(79, 0, tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(80, 0, tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(81, 0, tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "(82, 0, tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c721e5a59ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scratch/matting/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scratch/matting/model_final.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c721e5a59ce1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cuda)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#     return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scratch/matting/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scratch/matting/model_final.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-11c46647ccf9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, dataset, epoch, cuda)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#         print(iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/subramanyam.m/Deep-Image-Matting/code/DataLoader.ipynb\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m\"    return train_item\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m    ]\n\u001b[0;32m---> 44\u001b[0;31m   },\n\u001b[0m\u001b[1;32m     45\u001b[0m   {\n\u001b[1;32m     46\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"markdown\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/subramanyam.m/Deep-Image-Matting/code/DataLoader.ipynb\u001b[0m in \u001b[0;36mget_trimap\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m      6\u001b[0m    \"source\": [\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"### Load Packages\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m    ]\n\u001b[0m\u001b[1;32m      9\u001b[0m   },\n\u001b[1;32m     10\u001b[0m   {\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(cuda=True):\n",
    "    if cuda and not torch.cuda.is_available():\n",
    "        raise Exception(\"No GPU found\")\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(123)\n",
    "    else:\n",
    "        torch.manual_seed(123)\n",
    "    \n",
    "    fg_path = '/scratch/matting/dataset/Training_set/adobe/fg/'\n",
    "    bg_path = '/scratch/matting/dataset/train2014/'\n",
    "    alpha_path = '/scratch/matting/dataset/Training_set/adobe/alpha/'\n",
    "    vgg_path = '/scratch/matting/dataset/vgg_state_dict.pth'\n",
    "    fg_file = '/scratch/matting/dataset/Training_set/training_fg_names.txt'\n",
    "    bg_file = '/scratch/matting/dataset/Training_set/training_bg_names.txt'\n",
    "    epochs = 10\n",
    "    files_list = get_files_list(fg_file, bg_file)\n",
    "#     print(files_list)\n",
    "    dataset = load_dataset(fg_path, alpha_path, bg_path, files_list)\n",
    "    model = get_model()\n",
    "    vgg_dict = torch.load(vgg_path)\n",
    "    model = copy_pretrain_vals(model, vgg_dict)\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "#     save_model('/scratch/matting/model_testing.pth', model)\n",
    "#     return\n",
    "    for i in range(epochs):\n",
    "        train_model(model, optimizer, dataset, i, cuda)\n",
    "        save_model('/scratch/matting/model_' + str(i) + '.pth', model)\n",
    "    save_model('/scratch/matting/model_final.pth', model)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV Project",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
